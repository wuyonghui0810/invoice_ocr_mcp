#!/usr/bin/env python3
"""
ModelScope æ¨¡å‹ä¸‹è½½è„šæœ¬

ç”¨äºä¸‹è½½å’Œç¼“å­˜Invoice OCRæ‰€éœ€çš„æ‰€æœ‰æ¨¡å‹
"""

import os
import sys
import logging
import asyncio
from pathlib import Path
from typing import Dict, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

try:
    from modelscope import snapshot_download
    from modelscope.hub.api import HubApi
except ImportError:
    print("âŒ ModelScopeåº“æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…:")
    print("pip install modelscope")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ModelDownloader:
    """ModelScopeæ¨¡å‹ä¸‹è½½å™¨"""
    
    def __init__(self, cache_dir: str = "./cache/modelscope"):
        """åˆå§‹åŒ–ä¸‹è½½å™¨
        
        Args:
            cache_dir: æ¨¡å‹ç¼“å­˜ç›®å½•
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # é…ç½®ModelScopeç¼“å­˜ç›®å½•
        os.environ['MODELSCOPE_CACHE'] = str(self.cache_dir)
        
        # æ£€æŸ¥API Token
        self.api_token = os.getenv('MODELSCOPE_API_TOKEN')
        if not self.api_token:
            logger.warning("æœªè®¾ç½®MODELSCOPE_API_TOKENç¯å¢ƒå˜é‡ï¼Œå¯èƒ½å½±å“æ¨¡å‹ä¸‹è½½")
        
        # å®šä¹‰éœ€è¦ä¸‹è½½çš„æ¨¡å‹
        self.models = {
            "text_detection": {
                "model_id": "damo/cv_resnet18_ocr-detection-line-level_damo",
                "revision": "v1.0.2",
                "description": "æ–‡æœ¬æ£€æµ‹æ¨¡å‹ - ResNet18"
            },
            "text_recognition": {
                "model_id": "damo/cv_convnextTiny_ocr-recognition-general_damo", 
                "revision": "v1.0.1",
                "description": "æ–‡æœ¬è¯†åˆ«æ¨¡å‹ - ConvNext"
            },
            "invoice_classification": {
                "model_id": "damo/cv_resnest50_ocr-invoice-classification",
                "revision": "v1.0.0", 
                "description": "å‘ç¥¨åˆ†ç±»æ¨¡å‹ - ResNeSt50"
            },
            "info_extraction": {
                "model_id": "damo/nlp_structbert_document-classification_chinese-base",
                "revision": "v1.0.0",
                "description": "ä¿¡æ¯æŠ½å–æ¨¡å‹ - StructBERT"
            }
        }
        
        logger.info(f"æ¨¡å‹ç¼“å­˜ç›®å½•: {self.cache_dir}")
        logger.info(f"éœ€è¦ä¸‹è½½ {len(self.models)} ä¸ªæ¨¡å‹")
    
    def check_model_exists(self, model_name: str, model_id: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
        
        Args:
            model_name: æ¨¡å‹åç§°
            model_id: æ¨¡å‹ID
            
        Returns:
            æ¨¡å‹æ˜¯å¦å­˜åœ¨
        """
        # æ£€æŸ¥ç¼“å­˜ç›®å½•ä¸‹æ˜¯å¦æœ‰å¯¹åº”çš„æ¨¡å‹æ–‡ä»¶
        model_cache_path = self.cache_dir / "hub" / model_id.replace("/", "--")
        
        if model_cache_path.exists():
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹æ–‡ä»¶
            model_files = list(model_cache_path.rglob("*.bin")) + \
                         list(model_cache_path.rglob("*.pth")) + \
                         list(model_cache_path.rglob("*.onnx")) + \
                         list(model_cache_path.rglob("config.json"))
            
            if model_files:
                logger.info(f"âœ… æ¨¡å‹ {model_name} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                return True
        
        return False
    
    async def download_model(self, model_name: str, model_info: Dict[str, str]) -> bool:
        """ä¸‹è½½å•ä¸ªæ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
            model_info: æ¨¡å‹ä¿¡æ¯
            
        Returns:
            ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        model_id = model_info["model_id"]
        revision = model_info.get("revision", "master")
        description = model_info.get("description", "")
        
        logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
        logger.info(f"   æ¨¡å‹ID: {model_id}")
        logger.info(f"   ç‰ˆæœ¬: {revision}")
        logger.info(f"   æè¿°: {description}")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
        if self.check_model_exists(model_name, model_id):
            return True
        
        try:
            # ä¸‹è½½æ¨¡å‹
            model_path = snapshot_download(
                model_id=model_id,
                revision=revision,
                cache_dir=self.cache_dir
            )
            
            logger.info(f"âœ… æ¨¡å‹ {model_name} ä¸‹è½½æˆåŠŸ")
            logger.info(f"   æœ¬åœ°è·¯å¾„: {model_path}")
            
            # éªŒè¯ä¸‹è½½çš„æ¨¡å‹
            if self.verify_model(model_path):
                logger.info(f"âœ… æ¨¡å‹ {model_name} éªŒè¯é€šè¿‡")
                return True
            else:
                logger.error(f"âŒ æ¨¡å‹ {model_name} éªŒè¯å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ {model_name} ä¸‹è½½å¤±è´¥: {str(e)}")
            return False
    
    def verify_model(self, model_path: str) -> bool:
        """éªŒè¯æ¨¡å‹æ–‡ä»¶
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            
        Returns:
            éªŒè¯æ˜¯å¦é€šè¿‡
        """
        try:
            model_dir = Path(model_path)
            
            # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            required_files = ["config.json"]
            model_files = [".bin", ".pth", ".onnx"]
            
            # æ£€æŸ¥é…ç½®æ–‡ä»¶
            config_exists = any((model_dir / f).exists() for f in required_files)
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
            model_file_exists = any(
                list(model_dir.rglob(f"*{ext}")) for ext in model_files
            )
            
            if config_exists and model_file_exists:
                return True
            else:
                logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´: {model_path}")
                return False
                
        except Exception as e:
            logger.error(f"éªŒè¯æ¨¡å‹æ—¶å‡ºé”™: {e}")
            return False
    
    async def download_all_models(self, force_redownload: bool = False) -> Dict[str, bool]:
        """ä¸‹è½½æ‰€æœ‰æ¨¡å‹
        
        Args:
            force_redownload: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            
        Returns:
            å„æ¨¡å‹ä¸‹è½½ç»“æœ
        """
        logger.info("ğŸš€ å¼€å§‹ä¸‹è½½æ‰€æœ‰æ¨¡å‹...")
        
        if force_redownload:
            logger.info("âš ï¸  å¼ºåˆ¶é‡æ–°ä¸‹è½½æ¨¡å¼ï¼Œå°†å¿½ç•¥å·²å­˜åœ¨çš„æ¨¡å‹")
        
        results = {}
        
        # é¡ºåºä¸‹è½½æ¯ä¸ªæ¨¡å‹
        for model_name, model_info in self.models.items():
            if force_redownload:
                # åˆ é™¤å·²å­˜åœ¨çš„æ¨¡å‹
                model_id = model_info["model_id"]
                model_cache_path = self.cache_dir / "hub" / model_id.replace("/", "--")
                if model_cache_path.exists():
                    import shutil
                    shutil.rmtree(model_cache_path)
                    logger.info(f"ğŸ—‘ï¸  åˆ é™¤å·²å­˜åœ¨çš„æ¨¡å‹: {model_name}")
            
            success = await self.download_model(model_name, model_info)
            results[model_name] = success
            
            if success:
                print(f"âœ… {model_name}: ä¸‹è½½æˆåŠŸ")
            else:
                print(f"âŒ {model_name}: ä¸‹è½½å¤±è´¥")
        
        return results
    
    def get_cache_info(self) -> Dict[str, any]:
        """è·å–ç¼“å­˜ä¿¡æ¯
        
        Returns:
            ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        """
        cache_size = 0
        model_count = 0
        
        try:
            for root, dirs, files in os.walk(self.cache_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    cache_size += os.path.getsize(file_path)
                    if file.endswith(('.bin', '.pth', '.onnx')):
                        model_count += 1
        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}")
        
        return {
            "cache_dir": str(self.cache_dir),
            "cache_size_mb": cache_size / (1024 * 1024),
            "model_files": model_count,
            "total_models": len(self.models)
        }
    
    def print_cache_info(self):
        """æ‰“å°ç¼“å­˜ä¿¡æ¯"""
        info = self.get_cache_info()
        
        print("\nğŸ“Š ç¼“å­˜ä¿¡æ¯:")
        print(f"   ç¼“å­˜ç›®å½•: {info['cache_dir']}")
        print(f"   ç¼“å­˜å¤§å°: {info['cache_size_mb']:.1f} MB")
        print(f"   æ¨¡å‹æ–‡ä»¶: {info['model_files']} ä¸ª")
        print(f"   é¢„æœŸæ¨¡å‹: {info['total_models']} ä¸ª")
    
    def cleanup_cache(self):
        """æ¸…ç†ç¼“å­˜"""
        try:
            import shutil
            if self.cache_dir.exists():
                shutil.rmtree(self.cache_dir)
                logger.info(f"ğŸ—‘ï¸  ç¼“å­˜ç›®å½•å·²æ¸…ç†: {self.cache_dir}")
            self.cache_dir.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ModelScopeæ¨¡å‹ä¸‹è½½è„šæœ¬")
    parser.add_argument("--cache-dir", default="./cache/modelscope", 
                       help="æ¨¡å‹ç¼“å­˜ç›®å½•")
    parser.add_argument("--force", action="store_true",
                       help="å¼ºåˆ¶é‡æ–°ä¸‹è½½æ‰€æœ‰æ¨¡å‹")
    parser.add_argument("--cleanup", action="store_true",
                       help="æ¸…ç†ç¼“å­˜åé€€å‡º")
    parser.add_argument("--info", action="store_true",
                       help="ä»…æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯")
    
    args = parser.parse_args()
    
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = ModelDownloader(args.cache_dir)
    
    print("ğŸ¯ ModelScope æ¨¡å‹ä¸‹è½½å™¨")
    print("=" * 50)
    
    # å¤„ç†ä¸åŒå‘½ä»¤
    if args.cleanup:
        print("ğŸ—‘ï¸  æ¸…ç†æ¨¡å‹ç¼“å­˜...")
        downloader.cleanup_cache()
        print("âœ… ç¼“å­˜æ¸…ç†å®Œæˆ")
        return
    
    if args.info:
        downloader.print_cache_info()
        return
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not downloader.api_token:
        print("âš ï¸  è­¦å‘Š: æœªè®¾ç½® MODELSCOPE_API_TOKEN")
        print("   æŸäº›æ¨¡å‹å¯èƒ½éœ€è¦ç™»å½•æ‰èƒ½ä¸‹è½½")
        print("   è¯·è®¿é—® https://www.modelscope.cn/my/myaccesstoken è·å–Token")
    
    try:
        # ä¸‹è½½æ¨¡å‹
        results = await downloader.download_all_models(force_redownload=args.force)
        
        # æ˜¾ç¤ºç»“æœ
        print("\nğŸ“‹ ä¸‹è½½ç»“æœ:")
        success_count = sum(results.values())
        total_count = len(results)
        
        for model_name, success in results.items():
            status = "âœ…" if success else "âŒ"
            print(f"   {status} {model_name}")
        
        print(f"\nğŸ“Š æ€»ç»“:")
        print(f"   æˆåŠŸ: {success_count}/{total_count}")
        print(f"   å¤±è´¥: {total_count - success_count}/{total_count}")
        
        if success_count == total_count:
            print("\nğŸ‰ æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        else:
            print(f"\nâš ï¸  æœ‰ {total_count - success_count} ä¸ªæ¨¡å‹ä¸‹è½½å¤±è´¥")
            print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPI Tokenè®¾ç½®")
        
        # æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
        downloader.print_cache_info()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº†ä¸‹è½½")
    except Exception as e:
        logger.error(f"ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}", exc_info=True)
        print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")


if __name__ == "__main__":
    # Windowså¼‚æ­¥äº‹ä»¶å¾ªç¯å…¼å®¹æ€§
    if sys.platform == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    asyncio.run(main()) 